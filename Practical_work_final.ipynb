{"cells":[{"cell_type":"markdown","source":["# Practical Work in AI: Enhancing item relevance scores with psychology-based interest over time for music recommender systems\n","\n","Author: Laura Legat\n","Matriculation ID: 51868012"],"metadata":{"id":"nyy_wvOVHkv0"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56619,"status":"ok","timestamp":1721860568991,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"},"user_tz":-120},"id":"mXWWTg7lfuUD","outputId":"a3687a4f-024f-4075-918c-674162e1b3e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# import access to Google Drive files\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6QQ0W2yUgCrr"},"outputs":[],"source":["# import needed libraries\n","\n","import os\n","import torch\n","import sys\n","import pandas as pd\n","import importlib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csZJSJ4VMuPS"},"outputs":[],"source":["# create train-val-test sets for Ex2Vec training, as well as sequences for GRU4Rec training\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/preprocess.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8Jv9e4Jf7OF","outputId":"c0ae2e28-d73a-42c3-9eef-8f3c4c068237"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorboardX\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n"]}],"source":["!pip install tensorboardX"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37146,"status":"ok","timestamp":1721860612041,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"},"user_tz":-120},"id":"wfajT0rHgRIM","outputId":"51dfa9c4-2ceb-4498-b4e0-0f1af0d41736"},"outputs":[{"name":"stdout","output_type":"stream","text":["The size of the training set is: 1106989\n","The size of the validation set is: 156748\n","The size of the test set is: 320078\n"]}],"source":["# import custom code\n","\n","# Append the directory containing 'data_sampler' and 'ex2vec' to Python's search path\n","sys.path.append('/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI')\n","\n","# imports modules for preparing data and for training/evaluating the ex2vec model\n","import data_sampler\n","from ex2vec import Ex2VecEngine\n","\n","#import dir of gru4rec_pytorch module to python path in order to be able to access GRU4Rec model class to be able to load it\n","sys.path.append('/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork')\n","from gru4rec_pytorch\n","import evaluation as GRUeval"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1721860612042,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"},"user_tz":-120},"id":"1k-KR2WPgCCV","outputId":"e9d2f63a-1719-4205-cd99-dfdd1b7cee61"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using GPU: Tesla T4\n","Current device: cuda\n"]}],"source":["# Check if gpu is available\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    device_name = torch.cuda.get_device_name(device)\n","    print(f'Using GPU: {device_name}')\n","else:\n","    device = torch.device('cpu')\n","    print('Using CPU')\n","\n","print(f'Current device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XC3obowMLa3x"},"outputs":[],"source":["# check that deezer parameter file exists\n","param_file_path = '/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramfiles/deezer_paramfile.py'\n","assert os.path.isfile(param_file_path), f'Parameter file not found at {param_file_path}'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yy0ssBG2P9_M"},"outputs":[],"source":["# train baseline Ex2Vec with Ex2Vec item embeddings\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MTRuguVwPtI-"},"outputs":[],"source":["# train GRU4Rec\n","\n","\"\"\"\n","params: (from https://github.com/hidasib/GRU4Rec/blob/master/README.md)\n","  -t    Testset path\n","  -pf   Parameter file path\n","  -s    Path to save the state dict to\n","  -m    Calculate recall, MRR etc. at the given list length\n","  -ik   Item key\n","  -tk   Timestamp key\n","  -d    Device\n","\"\"\"\n","\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/run.py /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_train.csv -t /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_val.csv -pf /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramfiles/deezer_paramfile.py -s /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/models/GRU4Rec.pt -m 1 5 10 20 -ik \"itemId\" -tk \"timestamp\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vo-HfJyEPwid","outputId":"c6365ef4-3352-4b21-fa1c-4e5d258bf9b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["The size of the training set is: 1106989\n","The size of the validation set is: 156748\n","The size of the test set is: 320078\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","started training model:  ex2vec_BS512LR5e-05L_DIM64\n","Epoch 0 starts !\n","100% 2163/2163 [04:51<00:00,  7.42it/s]\n","[Evaluating Epoch 0] ACC = 0.5214, B_ACC = 0.5147, RECALL = 0.6449, F1 = 0.5133\n","Epoch 1 starts !\n","100% 2163/2163 [04:51<00:00,  7.42it/s]\n","[Evaluating Epoch 1] ACC = 0.5294, B_ACC = 0.5226, RECALL = 0.6561, F1 = 0.5210\n","Epoch 2 starts !\n","100% 2163/2163 [04:52<00:00,  7.39it/s]\n","[Evaluating Epoch 2] ACC = 0.5355, B_ACC = 0.5289, RECALL = 0.6573, F1 = 0.5278\n","Epoch 3 starts !\n","100% 2163/2163 [04:53<00:00,  7.38it/s]\n","[Evaluating Epoch 3] ACC = 0.5397, B_ACC = 0.5329, RECALL = 0.6653, F1 = 0.5315\n","Epoch 4 starts !\n","100% 2163/2163 [04:55<00:00,  7.32it/s]\n","[Evaluating Epoch 4] ACC = 0.5412, B_ACC = 0.5336, RECALL = 0.6829, F1 = 0.5308\n","Epoch 5 starts !\n","100% 2163/2163 [04:54<00:00,  7.33it/s]\n","[Evaluating Epoch 5] ACC = 0.5420, B_ACC = 0.5335, RECALL = 0.6991, F1 = 0.5290\n","Epoch 6 starts !\n","100% 2163/2163 [04:54<00:00,  7.35it/s]\n","[Evaluating Epoch 6] ACC = 0.5427, B_ACC = 0.5346, RECALL = 0.6922, F1 = 0.5310\n","Epoch 7 starts !\n","100% 2163/2163 [04:54<00:00,  7.36it/s]\n","[Evaluating Epoch 7] ACC = 0.5423, B_ACC = 0.5330, RECALL = 0.7139, F1 = 0.5267\n","Epoch 8 starts !\n","  3% 60/2163 [00:08<04:52,  7.18it/s]\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py\", line 66, in <module>\n","    engine.train_an_epoch(train_loader, epoch_id=epoch, embds_path=args.embds_path) # train 1 epoch\n","  File \"/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/engine.py\", line 59, in train_an_epoch\n","    loss = self.train_single_batch(user, item, rel_int, interest, embds_path=embds_path)\n","  File \"/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/engine.py\", line 29, in train_single_batch\n","    rating_pred = self.model(users, items, rel_int, embds_path=embds_path) # forward pass to get interest\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/ex2vec.py\", line 63, in forward\n","    all_item_embds = self.load_GRU4Rec_weights(embds_path)\n","  File \"/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/ex2vec.py\", line 135, in load_GRU4Rec_weights\n","    model_loaded = torch.load(GRU4RecModel_path)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1025, in load\n","    return _load(opened_zipfile,\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1446, in _load\n","    result = unpickler.load()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1416, in persistent_load\n","    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1381, in load_tensor\n","    storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage\n","KeyboardInterrupt\n"]}],"source":["# re-train Ex2Vec with GRU4Rec item embeddings\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py -ep /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/models/GRU4Rec.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XaD31WfOPz-1"},"outputs":[],"source":["# retrain Ex2Vec with GRU4Rec item embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKDD3P4mQFQ-"},"outputs":[],"source":["# compare performance"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyP5ArxKtBO6V6zU2BT0w7bZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}