{"cells":[{"cell_type":"markdown","source":["# Practical Work in AI: Enhancing item relevance scores with psychology-based interest over time for music recommender systems\n","\n","Author: Laura Legat\n","\n","Matriculation ID: 51868012"],"metadata":{"id":"nyy_wvOVHkv0"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21583,"status":"ok","timestamp":1722636338862,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"},"user_tz":-120},"id":"mXWWTg7lfuUD","outputId":"8a9f17f4-b1c5-4670-ae09-74190b13e36e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# import access to Google Drive files\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"6QQ0W2yUgCrr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722636394419,"user_tz":-120,"elapsed":4471,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"9aa798bc-2628-4ae8-e89f-ca8c0d800a06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","\n","All imports successful!\n"]}],"source":["# import needed libraries\n","\n","import os\n","import torch\n","import sys\n","import pandas as pd\n","import importlib\n","\n","!pip install optuna\n","import optuna\n","\n","!pip install tensorboardX\n","\n","print('\\nAll imports successful!')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":559,"status":"ok","timestamp":1722638549024,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"},"user_tz":-120},"id":"1k-KR2WPgCCV","outputId":"00cbcf29-b241-4c4b-b19d-b7fe21aea8ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using CPU\n","Current device: cpu\n"]}],"source":["# Check if gpu is available\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    device_name = torch.cuda.get_device_name(device)\n","    print(f'Using GPU: {device_name}')\n","else:\n","    device = torch.device('cpu')\n","    print('Using CPU')\n","\n","print(f'Current device: {device}')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"csZJSJ4VMuPS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722636428709,"user_tz":-120,"elapsed":16440,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"d5d261eb-12c0-42c0-bfdd-764de6d846af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Pre-processing dataset for Ex2Vec...\n","Saved processed.csv\n","Pre-processing dataset for GRU4Rec...\n","Saved sequenced files for GRU4Rec\n"]}],"source":["# create train-val-test sets for Ex2Vec training, as well as sequences for GRU4Rec training\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/preprocess.py -sl 50 -st 1 -sm Y"]},{"cell_type":"code","source":["# import custom code\n","\n","# Append the directory containing 'data_sampler' and 'ex2vec' to Python's search path\n","sys.path.append('/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI')\n","\n","# imports modules for preparing data and for training/evaluating the ex2vec model\n","import data_sampler\n","from ex2vec import Ex2VecEngine\n","\n","#import dir of gru4rec_pytorch module to python path in order to be able to access GRU4Rec model class to be able to load it\n","sys.path.append('/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork')\n","import gru4rec_pytorch\n","import evaluation as GRUeval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKeEyfrOITig","executionInfo":{"status":"ok","timestamp":1722636441311,"user_tz":-120,"elapsed":5758,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"62bbd208-0cb8-496b-adcf-24308fb04879"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["The size of the training set is: 18061\n","The size of the validation set is: 2562\n","The size of the test set is: 5213\n"]}]},{"cell_type":"code","source":["# training + hyperparameter optimization with seq_train.csv and seq_val.csv on GRU4Rec\n","\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/optuna_paropt.py /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_train.csv -opf /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramspaces/deezer_parspace_GRU4Rec.json -nt 2 -p /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/run.py -o /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/optim/best_params_gru4rec.json -mo gru4rec -t /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_val.csv -pf /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramfiles/deezer_paramfile.py -d cpu -m \"1 5 20\" -ik \"itemId\" -tk \"timestamp\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"HUImmQW6HBVh","executionInfo":{"status":"ok","timestamp":1722645874488,"user_tz":-120,"elapsed":225425,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"c860dc40-d2d6-4f26-fa6c-7ff36131aed0"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded parameters from file: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramfiles/deezer_paramfile.py\n","--------------------------------------------------------------------------------\n","PARAMETER SPACE:\n","\tPARAMETER name=loss \t type=categorical \t options: [bpr-max,cross-entropy]\n","\tPARAMETER name=constrained_embedding \t type=categorical \t options: [False,True]\n","\tPARAMETER name=embedding \t type=categorical \t options: [0,64]\n","\tPARAMETER name=elu_param \t type=categorical \t options: [0.5,1,0]\n","\tPARAMETER name=layers \t type=int \t range=[64..64] (step=1) \t UNIFORM scale\n","\tPARAMETER name=n_epochs \t type=categorical \t options: [2,3]\n","\tPARAMETER name=batch_size \t type=int \t range=[32..256] (step=16) \t UNIFORM scale\n","\tPARAMETER name=dropout_p_embed \t type=float \t range=[0.0..0.5] (step=0.05) \t UNIFORM scale\n","\tPARAMETER name=dropout_p_hidden \t type=float \t range=[0.0..0.7] (step=0.05) \t UNIFORM scale\n","\tPARAMETER name=learning_rate \t type=float \t range=[0.01..0.25] (step=0.005) \t UNIFORM scale\n","\tPARAMETER name=momentum \t type=float \t range=[0.0..0.9] (step=0.05) \t UNIFORM scale\n","\tPARAMETER name=n_sample \t type=categorical \t options: [1024,2048]\n","\tPARAMETER name=sample_alpha \t type=float \t range=[0.0..1.0] (step=0.1) \t UNIFORM scale\n","\tPARAMETER name=bpreg \t type=float \t range=[0.0..2.0] (step=0.05) \t UNIFORM scale\n","\tPARAMETER name=logq \t type=float \t range=[0.0..1.0] (step=0.1) \t UNIFORM scale\n","--------------------------------------------------------------------------------\n","\u001b[32m[I 2024-08-03 00:40:48,626]\u001b[0m A new study created in memory with name: no-name-82c9c489-e030-4c58-9371-337428fcb84c\u001b[0m\n","[1, 5, 20]\n","Creating GRU4Rec model on device \"cpu\"\n","SET   loss                    TO   bpr-max               (type: <class 'str'>)\n","SET   constrained_embedding   TO   False                 (type: <class 'bool'>)\n","SET   embedding               TO   64                    (type: <class 'int'>)\n","SET   elu_param               TO   0.5                   (type: <class 'float'>)\n","SET   layers                  TO   [64]                  (type: <class 'list'>)\n","SET   n_epochs                TO   2                     (type: <class 'int'>)\n","SET   batch_size              TO   32                    (type: <class 'int'>)\n","SET   dropout_p_embed         TO   0.35000000000000003   (type: <class 'float'>)\n","SET   dropout_p_hidden        TO   0.6000000000000001    (type: <class 'float'>)\n","SET   learning_rate           TO   0.13                  (type: <class 'float'>)\n","SET   momentum                TO   0.7000000000000001    (type: <class 'float'>)\n","SET   n_sample                TO   1024                  (type: <class 'int'>)\n","SET   sample_alpha            TO   0.0                   (type: <class 'float'>)\n","SET   bpreg                   TO   1.75                  (type: <class 'float'>)\n","SET   logq                    TO   0.4                   (type: <class 'float'>)\n","Loading training data...\n","Loading data from CSV file: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_train.csv\n","Started training\n","The dataframe is not sorted by SessionId, sorting now\n","Data sorting took 0.15s\n","Created sample store with 9765 batches of samples (type=GPU)\n","embedding first\n","embedding 2nd\n","Epoch1 --> loss: 26950.903580 \t(80.39s) \t[298.67 mb/s | 9558 e/s]\n","Epoch2 --> loss: 10.536480 \t(79.86s) \t[300.65 mb/s | 9621 e/s]\n","Total training time: 163.08s\n","Loading test data...\n","Loading data from CSV file: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_val.csv\n","Starting evaluation (cut-off=[1, 5, 20], using standard mode for tiebreaking)\n","Using existing item ID map\n","The dataframe is not sorted by SessionId, sorting now\n","Data sorting took 0.02s\n","Evaluation took 1.42s\n","Recall@1: 0.001551 MRR@1: 0.001551\n","Recall@5: 0.006412 MRR@5: 0.003023\n","Recall@20: 0.017429 MRR@20: 0.004013\n","PRIMARY METRIC: 0.001550982555443629\n","\u001b[32m[I 2024-08-03 00:43:35,320]\u001b[0m Trial 0 finished with value: 0.001550982555443629 and parameters: {'loss': 'bpr-max', 'constrained_embedding': False, 'embedding': 64, 'elu_param': 0.5, 'layers': 64, 'n_epochs': 2, 'batch_size': 32, 'dropout_p_embed': 0.35000000000000003, 'dropout_p_hidden': 0.6000000000000001, 'learning_rate': 0.13, 'momentum': 0.7000000000000001, 'n_sample': 1024, 'sample_alpha': 0.0, 'bpreg': 1.75, 'logq': 0.4}. Best is trial 0 with value: 0.001550982555443629.\u001b[0m\n","[1, 5, 20]\n","Creating GRU4Rec model on device \"cpu\"\n","SET   loss                    TO   cross-entropy         (type: <class 'str'>)\n","SET   constrained_embedding   TO   False                 (type: <class 'bool'>)\n","SET   embedding               TO   64                    (type: <class 'int'>)\n","SET   elu_param               TO   0.0                   (type: <class 'float'>)\n","SET   layers                  TO   [64]                  (type: <class 'list'>)\n","SET   n_epochs                TO   3                     (type: <class 'int'>)\n","SET   batch_size              TO   224                   (type: <class 'int'>)\n","SET   dropout_p_embed         TO   0.15000000000000002   (type: <class 'float'>)\n","SET   dropout_p_hidden        TO   0.45                  (type: <class 'float'>)\n","SET   learning_rate           TO   0.09999999999999999   (type: <class 'float'>)\n","SET   momentum                TO   0.4                   (type: <class 'float'>)\n","SET   n_sample                TO   1024                  (type: <class 'int'>)\n","SET   sample_alpha            TO   0.8                   (type: <class 'float'>)\n","SET   bpreg                   TO   0.05                  (type: <class 'float'>)\n","SET   logq                    TO   0.4                   (type: <class 'float'>)\n","Loading training data...\n","Loading data from CSV file: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_train.csv\n","Started training\n","The dataframe is not sorted by SessionId, sorting now\n","Data sorting took 0.15s\n","Created sample store with 9765 batches of samples (type=GPU)\n","embedding first\n","embedding 2nd\n","Epoch1 --> loss: 3.485350 \t(16.46s) \t[208.43 mb/s | 46688 e/s]\n","Epoch2 --> loss: 3.474446 \t(16.70s) \t[205.44 mb/s | 46018 e/s]\n","Epoch3 --> loss: 3.480666 \t(18.42s) \t[186.21 mb/s | 41712 e/s]\n","Total training time: 54.43s\n","Loading test data...\n","Loading data from CSV file: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_val.csv\n","Starting evaluation (cut-off=[1, 5, 20], using standard mode for tiebreaking)\n","Using existing item ID map\n","The dataframe is not sorted by SessionId, sorting now\n","Data sorting took 0.02s\n","Evaluation took 1.45s\n","Recall@1: 0.284134 MRR@1: 0.284134\n","Recall@5: 0.542524 MRR@5: 0.375160\n","Recall@20: 0.785245 MRR@20: 0.400735\n","PRIMARY METRIC: 0.2841336083529205\n","\u001b[32m[I 2024-08-03 00:44:33,337]\u001b[0m Trial 1 finished with value: 0.2841336083529205 and parameters: {'loss': 'cross-entropy', 'constrained_embedding': False, 'embedding': 64, 'elu_param': 0, 'layers': 64, 'n_epochs': 3, 'batch_size': 224, 'dropout_p_embed': 0.15000000000000002, 'dropout_p_hidden': 0.45, 'learning_rate': 0.09999999999999999, 'momentum': 0.4, 'n_sample': 1024, 'sample_alpha': 0.8, 'bpreg': 0.05, 'logq': 0.4}. Best is trial 1 with value: 0.2841336083529205.\u001b[0m\n"]}]},{"cell_type":"code","source":["# training + hyperparameter optim ex2vec\n","\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/optuna_paropt.py /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_train.csv -opf /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramspaces/deezer_parspace_Ex2Vec.json -nt 2 -p /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py -o /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/optim/best_params_ex2vec.json -mo ex2vec"],"metadata":{"id":"y5MnbNTata8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XC3obowMLa3x"},"outputs":[],"source":["# check that deezer parameter file exists\n","param_file_path = '/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramfiles/deezer_paramfile.py'\n","assert os.path.isfile(param_file_path), f'Parameter file not found at {param_file_path}'"]},{"cell_type":"code","source":["# train baseline Ex2Vec with Ex2Vec item embeddings, without hyperparameter tuning\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRD4nTX2VKoq","executionInfo":{"status":"ok","timestamp":1721953055838,"user_tz":-120,"elapsed":179259,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"788963f3-7dcf-40fa-e63b-ef9241ec5976"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The size of the training set is: 1106989\n","The size of the validation set is: 156748\n","The size of the test set is: 320078\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_baseline_BS512LR5e-05L_DIM64\n","Epoch 0 starts !\n","100% 2163/2163 [00:24<00:00, 88.63it/s]\n","[Evaluating Epoch 0] ACC = 0.5227, B_ACC = 0.5167, RECALL = 0.6356, F1 = 0.5161\n","Epoch 1 starts !\n","100% 2163/2163 [00:22<00:00, 94.09it/s]\n","[Evaluating Epoch 1] ACC = 0.5273, B_ACC = 0.5214, RECALL = 0.6375, F1 = 0.5210\n","Saving model at epoch  2\n","Saving model to  /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/chckpts/ex2vec_baseline_BS512LR5e-05L_DIM64_Epoch1_f10.5210.pt\n","Epoch 2 starts !\n","100% 2163/2163 [00:23<00:00, 93.75it/s] \n","[Evaluating Epoch 2] ACC = 0.5309, B_ACC = 0.5234, RECALL = 0.6703, F1 = 0.5207\n","Epoch 3 starts !\n","100% 2163/2163 [00:22<00:00, 94.45it/s]\n","[Evaluating Epoch 3] ACC = 0.5332, B_ACC = 0.5274, RECALL = 0.6415, F1 = 0.5272\n","Saving model at epoch  4\n","Saving model to  /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/chckpts/ex2vec_baseline_BS512LR5e-05L_DIM64_Epoch3_f10.5272.pt\n","Epoch 4 starts !\n","100% 2163/2163 [00:23<00:00, 94.01it/s]\n","[Evaluating Epoch 4] ACC = 0.5366, B_ACC = 0.5288, RECALL = 0.6818, F1 = 0.5255\n","Saving final model to  /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/models/ex2vec_baseline_BS512LR5e-05L_DIM64_Epoch4_f10.5255.pt\n","Model saved\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yy0ssBG2P9_M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721953776733,"user_tz":-120,"elapsed":268882,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"c3907c95-8cf5-4b14-ff37-303b09964636"},"outputs":[{"output_type":"stream","name":"stdout","text":["The size of the training set is: 1106989\n","The size of the validation set is: 156748\n","The size of the test set is: 320078\n","Starting hyperparameter optimization with Optuna...\n","\u001b[32m[I 2024-07-26 00:25:39,874]\u001b[0m A new study created in memory with name: no-name-389d2525-6798-487f-a8cf-ef36be329ce5\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS1024LR7.006541418858488e-05L_DIM64\n","Epoch 0 starts !\n","100% 1082/1082 [00:19<00:00, 54.69it/s]\n","[Evaluating Epoch 0] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0000, F1 = 0.3053\n","Epoch 1 starts !\n","100% 1082/1082 [00:19<00:00, 55.17it/s]\n","[Evaluating Epoch 1] ACC = 0.5249, B_ACC = 0.5193, RECALL = 0.6287, F1 = 0.5193\n","Epoch 2 starts !\n","100% 1082/1082 [00:19<00:00, 56.32it/s]\n","[Evaluating Epoch 2] ACC = 0.5329, B_ACC = 0.5291, RECALL = 0.6017, F1 = 0.5306\n","\u001b[32m[I 2024-07-26 00:27:07,248]\u001b[0m Trial 0 finished with value: 0.53058665004358 and parameters: {'BS': 1024, 'LR': 7.006541418858488e-05, 'L_DIM': 64, 'num_epoch': 3, 'l2_regularization': 0.00021181624507035602}. Best is trial 0 with value: 0.53058665004358.\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS1024LR3.0873983936439304e-05L_DIM64\n","Epoch 0 starts !\n","100% 1082/1082 [00:19<00:00, 56.44it/s]\n","[Evaluating Epoch 0] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0000, F1 = 0.3053\n","Epoch 1 starts !\n","100% 1082/1082 [00:19<00:00, 56.61it/s]\n","[Evaluating Epoch 1] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0000, F1 = 0.3053\n","Epoch 2 starts !\n","100% 1082/1082 [00:19<00:00, 56.51it/s]\n","[Evaluating Epoch 2] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0001, F1 = 0.3054\n","\u001b[32m[I 2024-07-26 00:28:31,821]\u001b[0m Trial 1 finished with value: 0.3053730555406402 and parameters: {'BS': 1024, 'LR': 3.0873983936439304e-05, 'L_DIM': 64, 'num_epoch': 3, 'l2_regularization': 7.553987346416723e-05}. Best is trial 0 with value: 0.53058665004358.\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 128)\n","  (embedding_item): Embedding(879, 128)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 128])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 128])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS1024LR1.5102933593789359e-05L_DIM128\n","Epoch 0 starts !\n","100% 1082/1082 [00:18<00:00, 57.01it/s]\n","[Evaluating Epoch 0] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0000, F1 = 0.3053\n","Epoch 1 starts !\n","100% 1082/1082 [00:19<00:00, 55.65it/s]\n","[Evaluating Epoch 1] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0000, F1 = 0.3053\n","\u001b[32m[I 2024-07-26 00:29:36,933]\u001b[0m Trial 2 finished with value: 0.3052547036716455 and parameters: {'BS': 1024, 'LR': 1.5102933593789359e-05, 'L_DIM': 128, 'num_epoch': 2, 'l2_regularization': 0.00016237445877272664}. Best is trial 0 with value: 0.53058665004358.\u001b[0m\n"]}],"source":["# train baseline Ex2Vec with Ex2Vec item embeddings, with hyperparameter tuning\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py -o Y"]},{"cell_type":"code","source":["# TODO: retrain ex2vec with the best parameters such that we can compare it to tuned Ex2Vec + GRU4Rec combo"],"metadata":{"id":"An9OwHqUfyXb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":26,"metadata":{"id":"MTRuguVwPtI-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722640677501,"user_tz":-120,"elapsed":12059,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"0b5817b7-27fc-452c-c297-d9b968159369"},"outputs":[{"output_type":"stream","name":"stdout","text":["hello1\n","hello2\n","type:  <class 'list'>\n","Loaded parameters from file: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramfiles/deezer_paramfile.py\n","Creating GRU4Rec model on device \"cpu\"\n","SET   loss                    TO   bpr-max   (type: <class 'str'>)\n","SET   constrained_embedding   TO   True      (type: <class 'bool'>)\n","SET   embedding               TO   0         (type: <class 'int'>)\n","SET   elu_param               TO   1.0       (type: <class 'float'>)\n","SET   layers                  TO   [64]      (type: <class 'list'>)\n","SET   n_epochs                TO   2         (type: <class 'int'>)\n","SET   batch_size              TO   50        (type: <class 'int'>)\n","SET   dropout_p_embed         TO   0.4       (type: <class 'float'>)\n","SET   dropout_p_hidden        TO   0.2       (type: <class 'float'>)\n","SET   learning_rate           TO   0.05      (type: <class 'float'>)\n","SET   momentum                TO   0.3       (type: <class 'float'>)\n","SET   n_sample                TO   2048      (type: <class 'int'>)\n","SET   sample_alpha            TO   0.3       (type: <class 'float'>)\n","SET   bpreg                   TO   0.9       (type: <class 'float'>)\n","SET   logq                    TO   0.0       (type: <class 'float'>)\n","Loading training data...\n","Loading data from CSV file: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_train.csv\n","Started training\n","The dataframe is not sorted by SessionId, sorting now\n","Data sorting took 0.14s\n","Created sample store with 4882 batches of samples (type=GPU)\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/run.py\", line 121, in <module>\n","  File \"/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/gru4rec_pytorch.py\", line 538, in fit\n","    opt.step() # update model params using the opimizer\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 391, in wrapper\n","    out = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/gru4rec_pytorch.py\", line 52, in step\n","    grad = grad.coalesce()\n","KeyboardInterrupt\n"]}],"source":["# train GRU4Rec without hyperparameter tuning\n","\n","\"\"\"\n","params: (from https://github.com/hidasib/GRU4Rec/blob/master/README.md)\n","  -t    Testset path\n","  -pf   Parameter file path\n","  -s    Path to save the state dict to\n","  -m    Calculate recall, MRR etc. at the given list length\n","  -ik   Item key\n","  -tk   Timestamp key\n","  -d    Device\n","\"\"\"\n","\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/run.py /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_train.csv -t /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_val.csv -pf /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramfiles/deezer_paramfile.py -s /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/models/GRU4Rec.pt -m 1 5 10 20 -d cpu -ik \"itemId\" -tk \"timestamp\""]},{"cell_type":"code","source":["#TODO: train GRU4Rec with hyperparameter tuning to get better item representation"],"metadata":{"id":"HO-y6k4Hio99"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vo-HfJyEPwid","outputId":"ac55ab4b-1046-47da-ffc0-91344445e5be","executionInfo":{"status":"ok","timestamp":1721956463253,"user_tz":-120,"elapsed":403548,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["The size of the training set is: 1106989\n","The size of the validation set is: 156748\n","The size of the test set is: 320078\n","Starting hyperparameter optimization with Optuna...\n","\u001b[32m[I 2024-07-26 00:59:51,047]\u001b[0m A new study created in memory with name: no-name-823705ee-b080-4154-88b7-a2c9faaa4b9e\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS2048LR2.6340995128658494e-05L_DIM64\n","Epoch 0 starts !\n","100% 541/541 [01:23<00:00,  6.48it/s]\n","[Evaluating Epoch 0] ACC = 0.4745, B_ACC = 0.5001, RECALL = 0.0002, F1 = 0.3055\n","Epoch 1 starts !\n","100% 541/541 [01:23<00:00,  6.49it/s]\n","[Evaluating Epoch 1] ACC = 0.4770, B_ACC = 0.5023, RECALL = 0.0089, F1 = 0.3145\n","\u001b[32m[I 2024-07-26 01:03:06,113]\u001b[0m Trial 0 finished with value: 0.31453844456830177 and parameters: {'BS': 2048, 'LR': 2.6340995128658494e-05, 'num_epoch': 2, 'l2_regularization': 2.5000572850072402e-05}. Best is trial 0 with value: 0.31453844456830177.\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS1024LR3.993595423102138e-05L_DIM64\n","Epoch 0 starts !\n","100% 1082/1082 [02:12<00:00,  8.20it/s]\n","[Evaluating Epoch 0] ACC = 0.5130, B_ACC = 0.5069, RECALL = 0.6251, F1 = 0.5063\n","Epoch 1 starts !\n","100% 1082/1082 [02:12<00:00,  8.14it/s]\n","[Evaluating Epoch 1] ACC = 0.5256, B_ACC = 0.5196, RECALL = 0.6382, F1 = 0.5190\n","Epoch 2 starts !\n","100% 1082/1082 [02:12<00:00,  8.15it/s]\n","[Evaluating Epoch 2] ACC = 0.5386, B_ACC = 0.5340, RECALL = 0.6236, F1 = 0.5350\n","\u001b[32m[I 2024-07-26 01:10:10,999]\u001b[0m Trial 1 finished with value: 0.5350191689549112 and parameters: {'BS': 1024, 'LR': 3.993595423102138e-05, 'num_epoch': 3, 'l2_regularization': 9.628868965385926e-05}. Best is trial 1 with value: 0.5350191689549112.\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS2048LR0.00012251184383735154L_DIM64\n","Epoch 0 starts !\n","100% 541/541 [01:15<00:00,  7.19it/s]\n","[Evaluating Epoch 0] ACC = 0.5314, B_ACC = 0.5259, RECALL = 0.6319, F1 = 0.5262\n","Epoch 1 starts !\n","100% 541/541 [01:15<00:00,  7.19it/s]\n","[Evaluating Epoch 1] ACC = 0.5550, B_ACC = 0.5500, RECALL = 0.6469, F1 = 0.5508\n","Epoch 2 starts !\n","100% 541/541 [01:15<00:00,  7.20it/s]\n","[Evaluating Epoch 2] ACC = 0.5721, B_ACC = 0.5666, RECALL = 0.6743, F1 = 0.5670\n","\u001b[32m[I 2024-07-26 01:14:23,506]\u001b[0m Trial 2 finished with value: 0.5670160892801643 and parameters: {'BS': 2048, 'LR': 0.00012251184383735154, 'num_epoch': 3, 'l2_regularization': 3.506705165700764e-05}. Best is trial 2 with value: 0.5670160892801643.\u001b[0m\n"]}],"source":["# re-train Ex2Vec with GRU4Rec item embeddings, with hyperparameter tuning\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py -ep /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/models/GRU4Rec.pt -o Y"]},{"cell_type":"markdown","source":["Best Ex2Vec with hyperparam tuning: ACC = 0.5329, B_ACC = 0.5291, RECALL = 0.6017, F1 = 0.5306\n","\n","Best Ex2Vec + GRU4Rec item embds with hyperparameter tuning: ACC = 0.5721, B_ACC = 0.5666, RECALL = 0.6743, F1 = 0.5670"],"metadata":{"id":"QaoEnv0_kvDo"}}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyO0R3Tc+P4pieMPpAUrscE1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}