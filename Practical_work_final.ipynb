{"cells":[{"cell_type":"markdown","source":["# Practical Work in AI: Enhancing item relevance scores with psychology-based interest over time for music recommender systems\n","\n","Author: Laura Legat\n","\n","Matriculation ID: 51868012"],"metadata":{"id":"nyy_wvOVHkv0"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21806,"status":"ok","timestamp":1721952820016,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"},"user_tz":-120},"id":"mXWWTg7lfuUD","outputId":"9daf688d-fa39-4de2-822c-09e2d0f352fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# import access to Google Drive files\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6QQ0W2yUgCrr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721952827834,"user_tz":-120,"elapsed":7823,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"f9f4a407-dc84-4bda-f533-c4332862473f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n","Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n"]}],"source":["# import needed libraries\n","\n","import os\n","import torch\n","import sys\n","import pandas as pd\n","import importlib\n","\n","!pip install optuna\n","import optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csZJSJ4VMuPS"},"outputs":[],"source":["# create train-val-test sets for Ex2Vec training, as well as sequences for GRU4Rec training\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/preprocess.py"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_8Jv9e4Jf7OF","outputId":"d84ffedf-713d-4be6-b31f-558eba87f601","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721952830294,"user_tz":-120,"elapsed":2471,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardX\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n"]}],"source":["!pip install tensorboardX"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35285,"status":"ok","timestamp":1721952865569,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"},"user_tz":-120},"id":"wfajT0rHgRIM","outputId":"5c0ff9d3-c47e-45ec-9d4e-ad05dfbef7ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["The size of the training set is: 1106989\n","The size of the validation set is: 156748\n","The size of the test set is: 320078\n"]}],"source":["# import custom code\n","\n","# Append the directory containing 'data_sampler' and 'ex2vec' to Python's search path\n","sys.path.append('/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI')\n","\n","# imports modules for preparing data and for training/evaluating the ex2vec model\n","import data_sampler\n","from ex2vec import Ex2VecEngine\n","\n","#import dir of gru4rec_pytorch module to python path in order to be able to access GRU4Rec model class to be able to load it\n","sys.path.append('/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork')\n","import gru4rec_pytorch\n","import evaluation as GRUeval"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1721952865570,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"},"user_tz":-120},"id":"1k-KR2WPgCCV","outputId":"b84acfb4-d8cc-4958-a0a5-6b374a2cff27"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU: NVIDIA L4\n","Current device: cuda\n"]}],"source":["# Check if gpu is available\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    device_name = torch.cuda.get_device_name(device)\n","    print(f'Using GPU: {device_name}')\n","else:\n","    device = torch.device('cpu')\n","    print('Using CPU')\n","\n","print(f'Current device: {device}')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XC3obowMLa3x","executionInfo":{"status":"ok","timestamp":1721952865571,"user_tz":-120,"elapsed":11,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}}},"outputs":[],"source":["# check that deezer parameter file exists\n","param_file_path = '/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramfiles/deezer_paramfile.py'\n","assert os.path.isfile(param_file_path), f'Parameter file not found at {param_file_path}'"]},{"cell_type":"code","source":["# train baseline Ex2Vec with Ex2Vec item embeddings, without hyperparameter tuning\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRD4nTX2VKoq","executionInfo":{"status":"ok","timestamp":1721953055838,"user_tz":-120,"elapsed":179259,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"788963f3-7dcf-40fa-e63b-ef9241ec5976"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["The size of the training set is: 1106989\n","The size of the validation set is: 156748\n","The size of the test set is: 320078\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_baseline_BS512LR5e-05L_DIM64\n","Epoch 0 starts !\n","100% 2163/2163 [00:24<00:00, 88.63it/s]\n","[Evaluating Epoch 0] ACC = 0.5227, B_ACC = 0.5167, RECALL = 0.6356, F1 = 0.5161\n","Epoch 1 starts !\n","100% 2163/2163 [00:22<00:00, 94.09it/s]\n","[Evaluating Epoch 1] ACC = 0.5273, B_ACC = 0.5214, RECALL = 0.6375, F1 = 0.5210\n","Saving model at epoch  2\n","Saving model to  /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/chckpts/ex2vec_baseline_BS512LR5e-05L_DIM64_Epoch1_f10.5210.pt\n","Epoch 2 starts !\n","100% 2163/2163 [00:23<00:00, 93.75it/s] \n","[Evaluating Epoch 2] ACC = 0.5309, B_ACC = 0.5234, RECALL = 0.6703, F1 = 0.5207\n","Epoch 3 starts !\n","100% 2163/2163 [00:22<00:00, 94.45it/s]\n","[Evaluating Epoch 3] ACC = 0.5332, B_ACC = 0.5274, RECALL = 0.6415, F1 = 0.5272\n","Saving model at epoch  4\n","Saving model to  /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/chckpts/ex2vec_baseline_BS512LR5e-05L_DIM64_Epoch3_f10.5272.pt\n","Epoch 4 starts !\n","100% 2163/2163 [00:23<00:00, 94.01it/s]\n","[Evaluating Epoch 4] ACC = 0.5366, B_ACC = 0.5288, RECALL = 0.6818, F1 = 0.5255\n","Saving final model to  /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/models/ex2vec_baseline_BS512LR5e-05L_DIM64_Epoch4_f10.5255.pt\n","Model saved\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"yy0ssBG2P9_M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721953776733,"user_tz":-120,"elapsed":268882,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"c3907c95-8cf5-4b14-ff37-303b09964636"},"outputs":[{"output_type":"stream","name":"stdout","text":["The size of the training set is: 1106989\n","The size of the validation set is: 156748\n","The size of the test set is: 320078\n","Starting hyperparameter optimization with Optuna...\n","\u001b[32m[I 2024-07-26 00:25:39,874]\u001b[0m A new study created in memory with name: no-name-389d2525-6798-487f-a8cf-ef36be329ce5\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS1024LR7.006541418858488e-05L_DIM64\n","Epoch 0 starts !\n","100% 1082/1082 [00:19<00:00, 54.69it/s]\n","[Evaluating Epoch 0] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0000, F1 = 0.3053\n","Epoch 1 starts !\n","100% 1082/1082 [00:19<00:00, 55.17it/s]\n","[Evaluating Epoch 1] ACC = 0.5249, B_ACC = 0.5193, RECALL = 0.6287, F1 = 0.5193\n","Epoch 2 starts !\n","100% 1082/1082 [00:19<00:00, 56.32it/s]\n","[Evaluating Epoch 2] ACC = 0.5329, B_ACC = 0.5291, RECALL = 0.6017, F1 = 0.5306\n","\u001b[32m[I 2024-07-26 00:27:07,248]\u001b[0m Trial 0 finished with value: 0.53058665004358 and parameters: {'BS': 1024, 'LR': 7.006541418858488e-05, 'L_DIM': 64, 'num_epoch': 3, 'l2_regularization': 0.00021181624507035602}. Best is trial 0 with value: 0.53058665004358.\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS1024LR3.0873983936439304e-05L_DIM64\n","Epoch 0 starts !\n","100% 1082/1082 [00:19<00:00, 56.44it/s]\n","[Evaluating Epoch 0] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0000, F1 = 0.3053\n","Epoch 1 starts !\n","100% 1082/1082 [00:19<00:00, 56.61it/s]\n","[Evaluating Epoch 1] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0000, F1 = 0.3053\n","Epoch 2 starts !\n","100% 1082/1082 [00:19<00:00, 56.51it/s]\n","[Evaluating Epoch 2] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0001, F1 = 0.3054\n","\u001b[32m[I 2024-07-26 00:28:31,821]\u001b[0m Trial 1 finished with value: 0.3053730555406402 and parameters: {'BS': 1024, 'LR': 3.0873983936439304e-05, 'L_DIM': 64, 'num_epoch': 3, 'l2_regularization': 7.553987346416723e-05}. Best is trial 0 with value: 0.53058665004358.\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 128)\n","  (embedding_item): Embedding(879, 128)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 128])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 128])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS1024LR1.5102933593789359e-05L_DIM128\n","Epoch 0 starts !\n","100% 1082/1082 [00:18<00:00, 57.01it/s]\n","[Evaluating Epoch 0] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0000, F1 = 0.3053\n","Epoch 1 starts !\n","100% 1082/1082 [00:19<00:00, 55.65it/s]\n","[Evaluating Epoch 1] ACC = 0.4744, B_ACC = 0.5000, RECALL = 0.0000, F1 = 0.3053\n","\u001b[32m[I 2024-07-26 00:29:36,933]\u001b[0m Trial 2 finished with value: 0.3052547036716455 and parameters: {'BS': 1024, 'LR': 1.5102933593789359e-05, 'L_DIM': 128, 'num_epoch': 2, 'l2_regularization': 0.00016237445877272664}. Best is trial 0 with value: 0.53058665004358.\u001b[0m\n"]}],"source":["# train baseline Ex2Vec with Ex2Vec item embeddings, with hyperparameter tuning\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py -o Y"]},{"cell_type":"code","source":["# TODO: retrain ex2vec with the best parameters such that we can compare it to tuned Ex2Vec + GRU4Rec combo"],"metadata":{"id":"An9OwHqUfyXb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"MTRuguVwPtI-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721954540366,"user_tz":-120,"elapsed":173409,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}},"outputId":"ff618a18-2454-4c7e-9f0e-07ca1df72268"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded parameters from file: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramfiles/deezer_paramfile.py\n","Creating GRU4Rec model on device \"cuda:0\"\n","SET   loss                    TO   bpr-max   (type: <class 'str'>)\n","SET   constrained_embedding   TO   True      (type: <class 'bool'>)\n","SET   embedding               TO   0         (type: <class 'int'>)\n","SET   elu_param               TO   1.0       (type: <class 'float'>)\n","SET   layers                  TO   [64]      (type: <class 'list'>)\n","SET   n_epochs                TO   2         (type: <class 'int'>)\n","SET   batch_size              TO   50        (type: <class 'int'>)\n","SET   dropout_p_embed         TO   0.4       (type: <class 'float'>)\n","SET   dropout_p_hidden        TO   0.2       (type: <class 'float'>)\n","SET   learning_rate           TO   0.05      (type: <class 'float'>)\n","SET   momentum                TO   0.3       (type: <class 'float'>)\n","SET   n_sample                TO   2048      (type: <class 'int'>)\n","SET   sample_alpha            TO   0.3       (type: <class 'float'>)\n","SET   bpreg                   TO   0.9       (type: <class 'float'>)\n","SET   logq                    TO   0.0       (type: <class 'float'>)\n","Loading training data...\n","Loading data from CSV file: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_train.csv\n","Started training\n","The dataframe is not sorted by SessionId, sorting now\n","Data is sorted in 0.54\n","Created sample store with 4882 batches of samples (type=GPU)\n","Epoch1 --> loss: 0.434765 \t(80.12s) \t[270.67 mb/s | 13534 e/s]\n","Epoch2 --> loss: 0.431027 \t(78.29s) \t[277.02 mb/s | 13851 e/s]\n","Total training time: 160.31s\n","Saving trained model to: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/models/GRU4Rec.pt\n","Loading test data...\n","Loading data from CSV file: /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_val.csv\n","Starting evaluation (cut-off=[1, 5, 10, 20], using standard mode for tiebreaking)\n","Using existing item ID map\n","The dataframe is not sorted by SessionId, sorting now\n","Data is sorted in 0.05\n","Evaluation took 3.82s\n","Recall@1: 0.230460 MRR@1: 0.230460\n","Recall@5: 0.499013 MRR@5: 0.322514\n","Recall@10: 0.671867 MRR@10: 0.345576\n","Recall@20: 0.798511 MRR@20: 0.354546\n"]}],"source":["# train GRU4Rec without hyperparameter tuning\n","\n","\"\"\"\n","params: (from https://github.com/hidasib/GRU4Rec/blob/master/README.md)\n","  -t    Testset path\n","  -pf   Parameter file path\n","  -s    Path to save the state dict to\n","  -m    Calculate recall, MRR etc. at the given list length\n","  -ik   Item key\n","  -tk   Timestamp key\n","  -d    Device\n","\"\"\"\n","\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/run.py /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_train.csv -t /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/data/seq_val.csv -pf /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/GRU4Rec_PyTorch_Fork/paramfiles/deezer_paramfile.py -s /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/models/GRU4Rec.pt -m 1 5 10 20 -ik \"itemId\" -tk \"timestamp\""]},{"cell_type":"code","source":["#TODO: train GRU4Rec with hyperparameter tuning to get better item representation"],"metadata":{"id":"HO-y6k4Hio99"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vo-HfJyEPwid","outputId":"ac55ab4b-1046-47da-ffc0-91344445e5be","executionInfo":{"status":"ok","timestamp":1721956463253,"user_tz":-120,"elapsed":403548,"user":{"displayName":"Laura Legat","userId":"08447403520972321571"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["The size of the training set is: 1106989\n","The size of the validation set is: 156748\n","The size of the test set is: 320078\n","Starting hyperparameter optimization with Optuna...\n","\u001b[32m[I 2024-07-26 00:59:51,047]\u001b[0m A new study created in memory with name: no-name-823705ee-b080-4154-88b7-a2c9faaa4b9e\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS2048LR2.6340995128658494e-05L_DIM64\n","Epoch 0 starts !\n","100% 541/541 [01:23<00:00,  6.48it/s]\n","[Evaluating Epoch 0] ACC = 0.4745, B_ACC = 0.5001, RECALL = 0.0002, F1 = 0.3055\n","Epoch 1 starts !\n","100% 541/541 [01:23<00:00,  6.49it/s]\n","[Evaluating Epoch 1] ACC = 0.4770, B_ACC = 0.5023, RECALL = 0.0089, F1 = 0.3145\n","\u001b[32m[I 2024-07-26 01:03:06,113]\u001b[0m Trial 0 finished with value: 0.31453844456830177 and parameters: {'BS': 2048, 'LR': 2.6340995128658494e-05, 'num_epoch': 2, 'l2_regularization': 2.5000572850072402e-05}. Best is trial 0 with value: 0.31453844456830177.\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS1024LR3.993595423102138e-05L_DIM64\n","Epoch 0 starts !\n","100% 1082/1082 [02:12<00:00,  8.20it/s]\n","[Evaluating Epoch 0] ACC = 0.5130, B_ACC = 0.5069, RECALL = 0.6251, F1 = 0.5063\n","Epoch 1 starts !\n","100% 1082/1082 [02:12<00:00,  8.14it/s]\n","[Evaluating Epoch 1] ACC = 0.5256, B_ACC = 0.5196, RECALL = 0.6382, F1 = 0.5190\n","Epoch 2 starts !\n","100% 1082/1082 [02:12<00:00,  8.15it/s]\n","[Evaluating Epoch 2] ACC = 0.5386, B_ACC = 0.5340, RECALL = 0.6236, F1 = 0.5350\n","\u001b[32m[I 2024-07-26 01:10:10,999]\u001b[0m Trial 1 finished with value: 0.5350191689549112 and parameters: {'BS': 1024, 'LR': 3.993595423102138e-05, 'num_epoch': 3, 'l2_regularization': 9.628868965385926e-05}. Best is trial 1 with value: 0.5350191689549112.\u001b[0m\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  LR_optim = trial.suggest_loguniform('LR', 1e-5, 1e-3)\n","/content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py:87: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  l2_regularization_optim = trial.suggest_loguniform('l2_regularization', 1e-5, 1e-2)\n","Ex2Vec(\n","  (user_lamb): Embedding(3623, 1)\n","  (user_bias): Embedding(3623, 1)\n","  (item_bias): Embedding(879, 1)\n","  (embedding_user): Embedding(3623, 64)\n","  (embedding_item): Embedding(879, 64)\n","  (logistic): Sigmoid()\n",")\n","global_lamb <class 'torch.Tensor'> torch.Size([])\n","alpha <class 'torch.Tensor'> torch.Size([])\n","beta <class 'torch.Tensor'> torch.Size([])\n","gamma <class 'torch.Tensor'> torch.Size([])\n","cutoff <class 'torch.Tensor'> torch.Size([])\n","user_lamb.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","user_bias.weight <class 'torch.Tensor'> torch.Size([3623, 1])\n","item_bias.weight <class 'torch.Tensor'> torch.Size([879, 1])\n","embedding_user.weight <class 'torch.Tensor'> torch.Size([3623, 64])\n","embedding_item.weight <class 'torch.Tensor'> torch.Size([879, 64])\n","Using validation set for evaluation\n","\n","Started training of model:  ex2vec_optim_BS2048LR0.00012251184383735154L_DIM64\n","Epoch 0 starts !\n","100% 541/541 [01:15<00:00,  7.19it/s]\n","[Evaluating Epoch 0] ACC = 0.5314, B_ACC = 0.5259, RECALL = 0.6319, F1 = 0.5262\n","Epoch 1 starts !\n","100% 541/541 [01:15<00:00,  7.19it/s]\n","[Evaluating Epoch 1] ACC = 0.5550, B_ACC = 0.5500, RECALL = 0.6469, F1 = 0.5508\n","Epoch 2 starts !\n","100% 541/541 [01:15<00:00,  7.20it/s]\n","[Evaluating Epoch 2] ACC = 0.5721, B_ACC = 0.5666, RECALL = 0.6743, F1 = 0.5670\n","\u001b[32m[I 2024-07-26 01:14:23,506]\u001b[0m Trial 2 finished with value: 0.5670160892801643 and parameters: {'BS': 2048, 'LR': 0.00012251184383735154, 'num_epoch': 3, 'l2_regularization': 3.506705165700764e-05}. Best is trial 2 with value: 0.5670160892801643.\u001b[0m\n"]}],"source":["# re-train Ex2Vec with GRU4Rec item embeddings, with hyperparameter tuning\n","!python /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/train.py -ep /content/drive/MyDrive/JKU/practical_work/Practical-Work-AI/models/GRU4Rec.pt -o Y"]},{"cell_type":"markdown","source":["Best Ex2Vec with hyperparam tuning: ACC = 0.5329, B_ACC = 0.5291, RECALL = 0.6017, F1 = 0.5306\n","\n","Best Ex2Vec + GRU4Rec item embds with hyperparameter tuning: ACC = 0.5721, B_ACC = 0.5666, RECALL = 0.6743, F1 = 0.5670"],"metadata":{"id":"QaoEnv0_kvDo"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOkLxV1+YzU4NqqnD0Y2QOO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}