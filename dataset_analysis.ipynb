{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Work in AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installs necessary libraries\n",
    "\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports for notebook to run\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Structure of processed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, certain statistics have to be observed on the given dataset in order to see if it is feasible to be sessionized and further used for training sequence-aware recommender systems models [a], such as GRU4Rec. \n",
    "\n",
    "For the analysis, we are working with the \"processed.csv\" dataset, which contains user-item interactions and represents a pre-processed version of the \"new_release_stream.csv\" file. A single row in this file looks like the following:\n",
    "\n",
    "`28,60,188807,1,[0.0],train`\n",
    "\n",
    "Here, the user with ID 28 listened to the track with ID 60 at timestamp 188807 (measured in seconds from first consumption). The track was listened to over 80% of its length (y = 1). The time interval (measured in hours) between when user 28 interacted with item 60 this time, versus the previous times, is 0.0, meaning it is the first interaction from user 28 to track 60. Based on the train-test-val split done during pre-processing (see `preprocess.py`), this interaction is part of the training set. \n",
    "\n",
    "Repetitive behavior is measured via the relational interval column (here [0.0]). Hence, the following lines from the dataset:\n",
    "\n",
    "`28,60,188807,1,[0.0],train`\n",
    "\n",
    "`28,60,188977,1,\"[0.04722222222222222, 0.0]\",train`\n",
    "\n",
    "`28,60,189155,0,\"[0.09666666666666666, 0.049444444444444444]\",train`\n",
    "\n",
    "have the following meaning with regards to the repetitions:\n",
    "\n",
    "`28,60,188807,1,[0.0],train` = User 28 consumes item 60 for the first time, thus no previous consumptions logged in the relational interval\n",
    "\n",
    "`28,60,188977,1,\"[0.04722222222222222, 0.0]\",train` = User 28 consumed item 60 for the first time 188977-188807 = 170s / 60 / 60 = 0.047222hrs ago\n",
    "\n",
    "`28,60,189155,0,\"[0.09666666666666666, 0.049444444444444444]\",train` = User 28 consumed item 60 since the last time 189155-188977 = 178s / 60 / 60 = 0.049444hrs ago and for the first time 0.049444444444444444 + 0.04722222222222222 = 0.09666666666666666 hrs ago"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the dataset is separated into two parts:\n",
    "\n",
    "- **Global measures**: e.g. average count of user-item interactions per set, average count of user-item interactions per item, etc.\n",
    "- **Session-based measures**: e.g. average number of sessions per user, average number of interactions per session, etc.\n",
    "\n",
    "We start by reading in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/processed.csv' # adjust as needed\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Global measures\n",
    "\n",
    "Firstly, we observe the number of interactions, unique users and unique items in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user-item interactions in total:  1583815\n",
      "Number of unique users:  3623\n",
      "Number of unique songs:  879\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of user-item interactions in total: \", len(df))\n",
    "print(\"Number of unique users: \", df.userId.nunique())\n",
    "print(\"Number of unique songs: \", df.itemId.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are consistent with the reportings from [b], after the authors implemented a $k^{item}$ and a $k^{user}$ pre-processing step, where each user has to have interacted with at least $k^{item}$ items and every item has to have been consumed by $k^{user}$ users. They decided on $k^{item} = k^{user} = 30$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Number of user-item interactions per set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user-item interactions for training-, test-, and validation set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>1423927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>80166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val</td>\n",
       "      <td>79722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     set    count\n",
       "0  train  1423927\n",
       "1   test    80166\n",
       "2    val    79722"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of rows per set, aka count size of training, test and validation dataset\n",
    "set_counts = df['set'].value_counts()\n",
    "\n",
    "# create df outof series and rename columns accordingly\n",
    "set_counts = set_counts.reset_index()\n",
    "set_counts.columns = ['set', 'count']\n",
    "\n",
    "print(\"Number of user-item interactions for training-, test-, and validation set:\")\n",
    "set_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, after splitting the data, we have numbers of interactions of train = ~1.4m, test = ~80.1k and validation = ~79.7k. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Average number of interactions, per user, and per item, in total and per set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, a user has 437 interactions in total.\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts = df['userId'].value_counts() # per userId, count the interactions\n",
    "avg_user_counts = user_interaction_counts.mean() # average interaction counts over all users\n",
    "\n",
    "print(f\"On average, a user has {int(avg_user_counts)} item interactions in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per set, a user has on average the following numbers of interactions: \n",
      " set\n",
      "test      22.126967\n",
      "train    393.024289\n",
      "val       22.004416\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts_per_set = df.groupby(['set', 'userId']).size()\n",
    "\n",
    "user_interaction_counts_per_set = user_interaction_counts_per_set.groupby(level='set').mean()\n",
    "\n",
    "print(\"Per set, a user has on average the following numbers of interactions: \\n\", user_interaction_counts_per_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, an item is interacted with 1801 times.\n"
     ]
    }
   ],
   "source": [
    "item_interaction_counts = df['itemId'].value_counts() # per track, count the interactions\n",
    "avg_item_counts = item_interaction_counts.mean() # average interaction counts over all items\n",
    "\n",
    "print(f\"On average, an item is interacted with {int(avg_item_counts)} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per set, on average, an item is interacted with the following number of times: \n",
      " set\n",
      "test       98.002445\n",
      "train    1619.939704\n",
      "val        98.422222\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "item_interaction_counts_per_set = df.groupby(['set', 'itemId']).size()\n",
    "\n",
    "item_interaction_counts_per_set = item_interaction_counts_per_set.groupby(level='set').mean()\n",
    "\n",
    "print(\"Per set, on average, an item is interacted with the following number of times: \\n\", item_interaction_counts_per_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Session-based measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interactions per user session:\n",
      "set   userId  session_id\n",
      "test  0       0             1\n",
      "              1             1\n",
      "              2             2\n",
      "              3             1\n",
      "              4             1\n",
      "                           ..\n",
      "val   3622    18            1\n",
      "              19            1\n",
      "              20            1\n",
      "              21            1\n",
      "              22            1\n",
      "Length: 414420, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# define cutoff value for sessionizing (here, 30 mins (1800s) is taken)\n",
    "def detect_sessions(group, threshold=1800):\n",
    "    # Sort values by timestamp to ensure correct session boundary detection\n",
    "    group = group.sort_values('timestamp')\n",
    "    # calc difference between consecutive timestamps timestamp_j - timestamp_i\n",
    "    time_diff = group['timestamp'].diff()\n",
    "    # sums up separate sessions - increases when a new session starts, otherwise it stays the same - this can be used as IDs which rows belong to which session\n",
    "    sessions = (time_diff > threshold).cumsum()\n",
    "    group['session_id'] = sessions\n",
    "    return group\n",
    "\n",
    "# for each set, group each user (unique users in training set, unique users in val set, unique users in test set) and detect their sessions\n",
    "sessionized_df = df.groupby(['set', 'userId']).apply(detect_sessions).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# Now group by set, user, and session_id to get number of sessions per set\n",
    "session_counts = sessionized_df.groupby(['set', 'userId', 'session_id']).size()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of interactions per user session:\")\n",
    "print(session_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId                    3623\n",
       "itemId                     879\n",
       "timestamp              1376164\n",
       "y                            2\n",
       "relational_interval    1202141\n",
       "set                          3\n",
       "session_id                 426\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessionized_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered sessions:\n",
      "set    userId  session_id\n",
      "test   341     1             20\n",
      "       2078    7             27\n",
      "       2796    4             33\n",
      "       2988    0             22\n",
      "train  0       24            31\n",
      "                             ..\n",
      "       3622    21            32\n",
      "               22            30\n",
      "val    1343    4             21\n",
      "       2146    2             31\n",
      "       2758    3             23\n",
      "Length: 9753, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# only consider sessions with at least 'interaction_threshold' number of interactions\n",
    "interaction_threshold = 20\n",
    "filtered_sessions = session_counts[session_counts >= interaction_threshold]\n",
    "\n",
    "print(\"Filtered sessions:\")\n",
    "print(filtered_sessions)\n",
    "\n",
    "# check number of reps, how many items are repeated in the same \n",
    "# how many sessions of user on average and length of sessions\n",
    "# avg interactions per session + per item + per user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId  session_id\n",
       "0       24            31\n",
       "        25            20\n",
       "        26            29\n",
       "        27            31\n",
       "        28            20\n",
       "                      ..\n",
       "3622    1             29\n",
       "        5             23\n",
       "        9             22\n",
       "        21            32\n",
       "        22            30\n",
       "Length: 9746, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sessions['train']\n",
    "# avg number of sessions per user\n",
    "\n",
    "#min items per user 5, min sessions per user 5, maybe reduce it to 3\n",
    "\n",
    "#accumulative approach - weighted average, mean, etc. weighted sum\n",
    "\n",
    "# partial sequences \n",
    "# combination of embeddings\n",
    "\n",
    "#put into tables\n",
    "\n",
    "#compare latent spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[a] Session-aware recommendation paper\n",
    "\n",
    "[b] Ex2Vec paper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supervised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
